{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:63: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import requests\n",
    "from StringIO import StringIO\n",
    "import skimage.measure\n",
    "import math\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = cPickle.load(fo)\n",
    "    return dict\n",
    "\n",
    "\n",
    "def squash_pixels(value):\n",
    "    if value<0:\n",
    "        return 0\n",
    "    elif value<255:\n",
    "        return value\n",
    "    else:\n",
    "        return 255\n",
    "\n",
    "def conv_2d_kernel(img_array, kernel, squash_pixel=True):\n",
    "    padded_array=np.pad(img_array, (1,1), 'constant')\n",
    "    kernel_width = kernel.shape[0]\n",
    "    kernel_height = kernel.shape[1]\n",
    "    \n",
    "    transformed_array = np.zeros(img_array.shape)\n",
    "    \n",
    "    for i in xrange(padded_array.shape[0] - kernel_width +1):\n",
    "        for j in xrange(padded_array.shape[1] - kernel_height + 1):\n",
    "            temp_array = padded_array[i:i+kernel_width, j:j+kernel_height]\n",
    "            if squash_pixel:\n",
    "                transformed_array[i,j] = squash_pixels(np.sum(temp_array*kernel))\n",
    "            else:\n",
    "                transformed_array[i,j] = np.sum(temp_array*kernel)                \n",
    "    return transformed_array\n",
    "                \n",
    "                    \n",
    "def relu_layer(x):\n",
    "        #turn all negative values in a matrix into zeros\n",
    "        z = np.zeros_like(x)\n",
    "        return np.where(x>z,x,z)\n",
    "    \n",
    "    \n",
    "def max_pooling(img_array, pool_size):\n",
    "    img_width = img_array.shape[0]\n",
    "    img_height = img_array.shape[1]\n",
    "    \n",
    "    res_array = skimage.measure.block_reduce(img_array, (pool_size,pool_size), np.max)\n",
    "    return res_array\n",
    "#print img\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "\n",
    "    \n",
    "input_layer_neurons = 16\n",
    "output_layer_neurons = 1        \n",
    "hidden_layer_neurons = 8\n",
    "w1 = np.random.uniform(size=(16, 8))\n",
    "b1 = np.random.uniform(size=(1, 8))\n",
    "w2 = np.random.uniform(size=(8,1))\n",
    "b2 = np.random.uniform(size=(1, 1))\n",
    "\n",
    "\n",
    "def fcl_for_training(dataset, epoch,y,lr):\n",
    "    global w1\n",
    "    global b1\n",
    "    global w2\n",
    "    global b2\n",
    "    for i in range(epoch):\n",
    "        #FEED FORWARD\n",
    "        hidden_layer_input = np.dot(dataset,w1) + b1\n",
    "        hidden_layer_activations = sigmoid(hidden_layer_input)\n",
    "        output_layer_input = np.dot(hidden_layer_activations, w2) + b2\n",
    "        output = sigmoid(output_layer_input)\n",
    "\n",
    "\n",
    "\n",
    "        #BACKPROPAGATION\n",
    "        E = y-output\n",
    "        slope_output_layer = sigmoid_derivative(output)\n",
    "        slope_hidden_layer = sigmoid_derivative(hidden_layer_activations)\n",
    "        d_output = E * slope_output_layer\n",
    "        error_at_hidden_layer = d_output.dot(w2.T)\n",
    "        d_hidden_layer = error_at_hidden_layer*slope_hidden_layer\n",
    "        w2 += hidden_layer_activations.T.dot(d_output)*lr\n",
    "        b2 += np.sum(d_output, axis=0, keepdims=True) * lr\n",
    "        w1 += dataset.T.dot(d_hidden_layer) * lr\n",
    "        b1 += np.sum(d_hidden_layer, axis=0, keepdims=True) * lr\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def fcl_for_testing(dataset, epoch):\n",
    "    global w1\n",
    "    global b1\n",
    "    global w2\n",
    "    global b2\n",
    "    for i in range(epoch):                    \n",
    "        hidden_layer_input = np.dot(dataset,w1) + b1\n",
    "        hidden_layer_activations = sigmoid(hidden_layer_input)\n",
    "        output_layer_input = np.dot(hidden_layer_activations, w2) + b2\n",
    "        output = sigmoid(output_layer_input)\n",
    "        \n",
    "    return output\n",
    "            \n",
    "    \n",
    "#img = unpickle('cifar-10-batches-py/data_batch_1')['data']\n",
    "#labels = unpickle(\"cifar-10-batches-py/data_batch_1\")['labels']\n",
    "\n",
    "kernel1 = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n",
    "X = []\n",
    "for i in range(1,50000):\n",
    "    img = np.array(Image.open(\"train/%d.png\" %i))\n",
    "    img = img[:,:,0]\n",
    "    X.append(img)\n",
    "\n",
    "epoch = 5000\n",
    "lr = 0.1\n",
    "\n",
    "\n",
    "#label_names =  pickle.load(open(\"cifar-10-batches-py/batches.meta\", 'rb'))['label_names']\n",
    "#print label_names\n",
    "\n",
    "\n",
    "file_to_read_from = 'trainLabels.csv'\n",
    "\n",
    "#initializing as many lists as the columns you want (not all)\n",
    "col1, col2, col3 = [], [], []\n",
    "with open(file_to_read_from, 'r') as file_in:\n",
    "    reader = csv.reader(file_in, delimiter=',') #might as well be ',', '\\t' etc\n",
    "    for row in reader:\n",
    "        col1.append(row[0])\n",
    "        col2.append(row[1])\n",
    "\n",
    "map_dict = {\n",
    "    \"frog\": np.array([[1],[0],[0], [0], [0],[0],[0], [0], [0],[0],[0], [0], [0],[0], [0], [0]])  ,\n",
    "    \"airplane\": np.array([[0],[1],[0], [0], [0],[0],[0], [0], [0],[0],[0], [0], [0],[0], [0], [0]]),\n",
    "    \"automobile\": np.array([[0],[0],[1], [0], [0],[0],[0], [0], [0],[0],[0], [0], [0],[0], [0], [0]]),\n",
    "    \"truck\": np.array([[0],[0],[0], [1], [0],[0],[0], [0], [0],[0],[0], [0], [0],[0], [0], [0]]),\n",
    "    \"deer\": np.array([[0],[0],[0], [0], [1],[0],[0], [0], [0],[0],[0], [0], [0],[0], [0], [0]]),\n",
    "    \"bird\": np.array([[0],[0],[0], [0], [0],[1],[0], [0], [0],[0],[0], [0], [0],[0], [0], [0]]),\n",
    "    \"cat\": np.array([[0],[0],[0], [0], [0],[0],[1], [0], [0],[0],[0], [0], [0],[0], [0], [0]]),\n",
    "    \"dog\": np.array([[0],[0],[0], [0], [0],[0],[0], [1], [0],[0],[0], [0], [0],[0], [0], [0]]),\n",
    "    \"horse\": np.array([[0],[0],[0], [0], [0],[0],[0], [0], [1],[0],[0], [0], [0],[0], [0], [0]]),\n",
    "    \"ship\": np.array([[0],[0],[0], [0], [0],[0],[0], [0], [0],[1],[0], [0], [0],[0], [0], [0]])\n",
    "}\n",
    "\n",
    "\n",
    "i=0\n",
    "\n",
    "for img_arr in X:\n",
    "    im1 = conv_2d_kernel(img_arr, kernel1)\n",
    "    im2 = relu_layer(im1)\n",
    "    im3 = max_pooling(im2, 2)\n",
    "    fin_op = fcl_for_training(im3, epoch, map_dict[col2[i]], lr)\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "img_arra = np.array(Image.open(\"deer.png\"))\n",
    "img_arra = img_array[:,:,0]\n",
    "ime1 = conv_2d_kernel(img_arra, kernel1)\n",
    "ime2 = relu_layer(ime1)\n",
    "ime3 = max_pooling(im2, 2)\n",
    "print fcl_for_testing(ime3, epoch)\n",
    "\n",
    "\n",
    "    \n",
    "#y1=conv_2d_kernel(img, kernel1)\n",
    "#y1=relu_layer(y1)\n",
    "#y=max_pooling(y1,2)\n",
    "#fcl(X, epoch,ao,lr)\n",
    "\n",
    "\n",
    "'''\n",
    "f,ax_array = plt.subplots(3)\n",
    "f.set_figheight(10)\n",
    "f.set_figwidth(15)\n",
    "ax_array[0].imshow(img, cmap = plt.get_cmap('gray'))\n",
    "ax_array[1].imshow(y1, cmap = plt.get_cmap('gray'))\n",
    "ax_array[2].imshow(y, cmap = plt.get_cmap('gray'))\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
